{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "BBjBqw7yHu7m",
   "metadata": {
    "id": "BBjBqw7yHu7m"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/avakanski/LASSO_MOGAT/blob/main/LASSO_MOGAT.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jsnebcpV8nRd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18874,
     "status": "ok",
     "timestamp": 1741373808260,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "jsnebcpV8nRd",
    "outputId": "d33540c9-516a-44d5-82db-92d7f35ba06e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TT1Kbn-J8qsE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3112,
     "status": "ok",
     "timestamp": 1741373811374,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "TT1Kbn-J8qsE",
    "outputId": "cde03164-1c97-4437-e344-6f5563898511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YB3AFUVB8v9G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13820,
     "status": "ok",
     "timestamp": 1741373825195,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "YB3AFUVB8v9G",
    "outputId": "a23857e4-24e1-4ae4-9379-b1bbd2209936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from torch.nn import BatchNorm1d, LeakyReLU\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import datetime\n",
    "now = datetime.datetime.now\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3nAX0dR89yX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1209,
     "status": "ok",
     "timestamp": 1741373826405,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "d3nAX0dR89yX",
    "outputId": "3e2b4c23-109e-4380-8abc-b52ef07987e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-dbafd6daffc1>:23: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  edges = ppi_filtered[['stringId_A', 'stringId_B']].applymap(lambda x: protein_to_id[x])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the PPI data\n",
    "ppi_file_path = 'drive/My Drive/Projects/Gene_Expression_Project/PPI.csv'\n",
    "ppi_df = pd.read_csv(ppi_file_path)\n",
    "\n",
    "# Step 2: Concatenate 'stringId_A' and 'stringId_B' to calculate the number of connections (degree)\n",
    "all_proteins = pd.concat([ppi_df['stringId_A'], ppi_df['stringId_B']])\n",
    "\n",
    "# Step 3: Count the number of connections for each protein\n",
    "protein_connections = all_proteins.value_counts()\n",
    "\n",
    "# Step 4: Define a degree threshold to select only highly connected proteins (e.g., 200 or more connections)\n",
    "degree_threshold = 200\n",
    "high_degree_proteins = protein_connections[protein_connections >= degree_threshold].index\n",
    "\n",
    "# Step 5: Filter the PPI data to include only edges where both proteins have a high number of connections\n",
    "ppi_filtered = ppi_df[ppi_df['stringId_A'].isin(high_degree_proteins) & ppi_df['stringId_B'].isin(high_degree_proteins)]\n",
    "\n",
    "# Step 6: Map the high-degree proteins to unique node IDs\n",
    "proteins = pd.concat([ppi_filtered['stringId_A'], ppi_filtered['stringId_B']]).unique()\n",
    "protein_to_id = {protein: idx for idx, protein in enumerate(proteins)}\n",
    "\n",
    "# Step 7: Create edge index (this will be the input for GAT)\n",
    "edges = ppi_filtered[['stringId_A', 'stringId_B']].applymap(lambda x: protein_to_id[x])\n",
    "edge_index = torch.tensor(edges.values.T, dtype=torch.long).to(device)  # Move edge index to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z-l6Xit-890Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13729,
     "status": "ok",
     "timestamp": 1741373840138,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "Z-l6Xit-890Y",
    "outputId": "51255fec-5476-40a2-bc58-50d64f162294"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-07 18:57:06--  https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n",
      "Resolving www.webpages.uidaho.edu (www.webpages.uidaho.edu)... 129.101.105.230\n",
      "Connecting to www.webpages.uidaho.edu (www.webpages.uidaho.edu)|129.101.105.230|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 123599052 (118M) [application/octet-stream]\n",
      "Saving to: ‘mRNA_miRNA_Meth_integrated.csv’\n",
      "\n",
      "mRNA_miRNA_Meth_int 100%[===================>] 117.87M  17.5MB/s    in 9.5s    \n",
      "\n",
      "2025-03-07 18:57:16 (12.4 MB/s) - ‘mRNA_miRNA_Meth_integrated.csv’ saved [123599052/123599052]\n",
      "\n",
      "Number of classes: 32\n",
      "Number of samples: 8464\n",
      "Number of Features: 2793\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Load and preprocess the multi-omics data\n",
    "!wget https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n",
    "file_path = 'mRNA_miRNA_Meth_integrated.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "Y = df.iloc[:, -1].copy()\n",
    "\n",
    "# Remove non-numeric columns\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "X = df.values\n",
    "\n",
    "num_classes = len(set(Y))\n",
    "print(\"Number of classes:\", num_classes)\n",
    "num_samples = X.shape[0]\n",
    "print(\"Number of samples:\", num_samples)\n",
    "num_Features = X.shape[1]\n",
    "print(\"Number of Features:\", num_Features)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "\n",
    "# Step 9: Create PyTorch Geometric data object using the edge_index from the filtered PPI network\n",
    "data = Data(x=torch.tensor(X, dtype=torch.float).to(device), edge_index=edge_index)  # Move data to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XiCishdy9HqP",
   "metadata": {
    "id": "XiCishdy9HqP"
   },
   "outputs": [],
   "source": [
    "# Step 10: Define the GAT model\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        hidden_feats = 1024\n",
    "        self.conv1 = GATConv(X.shape[1], hidden_feats, heads=8)\n",
    "        self.bn1 = BatchNorm1d(hidden_feats * 8)\n",
    "        self.relu1 = LeakyReLU()\n",
    "        self.conv2 = GATConv(hidden_feats * 8, hidden_feats // 2, heads=4)\n",
    "        self.bn2 = BatchNorm1d(hidden_feats // 2 * 4)\n",
    "        self.relu2 = LeakyReLU()\n",
    "        self.conv3 = GATConv(hidden_feats // 2 * 4, hidden_feats // 4, heads=2)\n",
    "        self.bn3 = BatchNorm1d(hidden_feats // 4 * 2)\n",
    "        self.relu3 = LeakyReLU()\n",
    "        self.conv4 = GATConv(hidden_feats // 4 * 2, 32, heads=1)\n",
    "        self.bn4 = BatchNorm1d(32)\n",
    "        self.relu4 = LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.3)  # Set dropout to 0.3\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Step 11: Set up K-fold cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "accuracy_scores = []\n",
    "F1Measure = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969d149",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228951,
     "status": "ok",
     "timestamp": 1741374069109,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "3969d149",
    "outputId": "42eb006f-0805-4de9-9bbd-7a97c6043406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:03:48.903006\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Training and Evaluation\n",
    "t = now()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Convert to PyTorch tensors and move them to the GPU\n",
    "    X_train = torch.FloatTensor(X_train).to(device)\n",
    "    y_train = torch.LongTensor(y_train).to(device)\n",
    "    X_test = torch.FloatTensor(X_test).to(device)\n",
    "    y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "    # Create train/test data using the same PPI edge_index\n",
    "    train_data = Data(x=X_train, edge_index=edge_index)\n",
    "    test_data = Data(x=X_test, edge_index=edge_index)\n",
    "\n",
    "    # Create the GAT model and move it to the GPU\n",
    "    model = GAT().to(device)  # Move model to device\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)  # Set learning rate to 0.001 and weight_decay to 0\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_data)\n",
    "        loss = criterion(out, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(test_data)\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            acc = accuracy_score(y_test.cpu().numpy(), pred.cpu().numpy())\n",
    "            # print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {acc:.4f}')\n",
    "            scheduler.step(acc)\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(test_data)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        test_acc = accuracy_score(y_test.cpu().numpy(), pred.cpu().numpy())\n",
    "        precision = precision_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro')\n",
    "        recall = recall_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro')\n",
    "        f1 = f1_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro')\n",
    "\n",
    "        accuracy_scores.append(test_acc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        F1Measure.append(f1)\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D4UiJ4EF9WD7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1741374069155,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "D4UiJ4EF9WD7",
    "outputId": "344c3ea0-cca0-4978-f9d9-8a60d32d9bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.9548679795402848\n",
      "Accuracy std sev = 0.003472672364425694\n",
      "Average precision = 0.9420488913494924\n",
      "Precision std sev = 0.00542539661054963\n",
      "Average recall = 0.9397636517868285\n",
      "Recall std sev = 0.014076609894764577\n",
      "Average F1 score = 0.9373233450710761\n",
      "F1 std dev = 0.012440618684223055\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average metrics across all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(F1Measure)\n",
    "\n",
    "print(\"Average accuracy =\", average_accuracy)\n",
    "print(\"Accuracy std sev =\", np.std(accuracy_scores))\n",
    "print(\"Average precision =\", average_precision)\n",
    "print(\"Precision std sev =\", np.std(precision_scores))\n",
    "print(\"Average recall =\", average_recall)\n",
    "print(\"Recall std sev =\", np.std(recall_scores))\n",
    "print(\"Average F1 score =\", average_f1)\n",
    "print(\"F1 std dev =\", np.std(F1Measure))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
